\documentclass[12pt,a4paper,spanish]{report}
\usepackage{listings}
\usepackage{titlesec}
\usepackage{amssymb, latexsym}
\usepackage[spanish]{babel}
%\selectlanguage{spanish}  
\usepackage[latin1]{inputenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{tocloft}

%\setlength\cftparskip{-2pt}
%\setlength\cftbeforechapskip{0pt}

\hoffset=-0.5cm
\voffset=-1.5cm
\textwidth=15cm
\textheight=22cm

\setlength{\parskip}{\baselineskip}

\titleformat{\chapter}
{\Huge\bfseries}{\thechapter . }{0pt}
{}
\titlespacing{\chapter}{0pt}{-20pt}{20pt}


\begin{document}

\begin{titlepage}
\begin{center}
\vspace*{0in}
\begin{figure}[htb]
\begin{center}
\includegraphics[width=15cm,height=10cm]{portada/portada4.jpg}
\end{center}
\end{figure}
\large{UNIVERSIDAD COMPLUTENSE DE MADRID}\\
\vspace*{0.07in}
\normalsize{FACULTAD DE CC.MATEMÁTICAS}\\
\vspace*{0.3in}
\begin{LARGE}
\textbf{VISIÓN COMPUTARIZADA APLICADA A LA BIOLOGÍA} \\
\end{LARGE}
\vspace*{0.3in}
\rule{80mm}{0.1mm}\\
\vspace*{0.1in}
\begin{large}
Autora: Gema Valdés Berlinches \\
Supervisado por: Carlos Gregorio Rodríguez \\
\end{large}
\end{center}
\end{titlepage}


\newpage
\tableofcontents

\newpage
\chapter{Introducción/Presentación}
\begin{itemize}
\item computer vision
\item licenciatura
\item relación con matemáticas
\item ...
\item ...
\item objetivos
\end{itemize}


%\part{Proyecto}
\chapter{Presentación y objetivos (del proyecto)}

Dada una base de datos con imágenes de mariposas deseamos encontrar un método que nos facilite la tarea de ver si una nueva mariposa la tenemos ya clasificada o, por el contrario, todavía no se encuentra dentro de la colección. Para ello, necesitamos discrimar las imágenes de diferentes formas y así seleccionar las más parecidas a la nueva, para que de esta manera, sea más fácil tomar la decisión de si está clasificada o no, ya que tendremos que fijarnos en un número muy reducido de ejemplares en vez de tener que mirar todas una por una.
 
El objetivo del trabajo es crear un programa que, utilizando la imagen de la nueva mariposa, vaya comparando ésta con cada una de las que tenemos ya guardadas en nuestra base de datos y que decida, según diferentes criterios basados en el color y la forma, si son suficientemente parecidas y es seleccionada, o no lo son y es descartada, obteniendo como resultado el conjunto de todas las seleccionadas, es decir, las más semejantes a la que deseamos añadir.

Las imágenes que vamos a utilizar en el trabajo están sacadas de la página web de Proyecto Mariposa \url{proyectomariposa.net}, que es un proyecto cuyo objetivo es crear una base de datos de la biodiversidad de las mariposas diurnas de Colombia y testar la utilidad del código de barras genético. De todas las imágenes que están disponibles vamos a trabajar sólo con las que tienen debajo un \textit{color-check} (véase \textit{Figura \ref{qpcard}}). Por tanto, las muestras tienen un ejemplar de mariposa en la parte superior que está encuadrado por dos reglas, una a la izquierda y otra debajo, que nos van a indicar el tamaño y debajo de la regla inferior un \textit{color-check}(véase \textit{Figura \ref{ejemplar}}).

\begin{figure}[ht]
\begin{center}
\includegraphics[width=8cm]{imagenes/qp.jpg}
\end{center}
\caption{Color-check.}
\label{qpcard}
\end{figure}\begin{figure}[ht]

\begin{center}
\includegraphics[width=10cm]{imagenes/ejemplar.jpg}
\end{center}
\caption{Imagen de una de las muestras.}
\label{ejemplar}
\end{figure}



Los principales pasos que hay que llevar a cabo son:
\begin{itemize}
\item Hacer un preprocesamiento de las imágenes, haciendo que todas estén a la misma escala, para que los resultados de los análisis posteriores sean más reales.
\item Encontrar la silueta de la mariposa para poder aislarla del fondo, llegando a obtener una 'máscara' (imagen binaria), en la que los puntos del cuerpo de la mariposa son blancos y el resto negros. Esta máscara se utilizará luego para las comparaciones.
\item Hacer las comparaciones por color y por forma utilizando histogramas para el color y distintas propiedades de la silueta de la mariposa (como por ejemplo el área) para la forma. Para que los datos que analizamos sean sólo de la mariposa utilizaremos la máscara.
\end{itemize}  

\chapter{Preprocesando las muestras}
Las imágenes que he obtenido de la base de datos de Proyecto Mariposa están a distinta escala, por tanto, es necesario llevar a cabo un proceso previo de reescalado para hacer que todas queden igual y no obtener datos falsos en las posteriores comparaciones.\\
Para hacer este reescalado primero voy a tratar de encontrar el rectángulo de colores en cada imagen y después hacer que éste tenga el mismo tamaño en cada una de ellas (véase \textit{Figura \ref{igual-qp}}), así, 1cm de los que marcan las reglas de las imágenes va a equivaler al mismo número de píxeles en cada una de ellas.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=10cm]{imagenes/Imagen1.jpg}
\end{center}
\caption{Todas las \textit{color-check} tienen el mismo tamaño.}
\label{igual-qp}
\end{figure}


\section{Encontrando el \textit{color-check}}
Vamos a intentar encontrar la posición del \textit{color-check} encontrando su contorno y para que esto sea más sencillo, hay que intentar hacer que destaque sobre el fondo. 

Empezamos probando con diferentes \textit{thresholds} aplicados sobre toda la imagen. Utilizando los programas test\_threshold.py y adapThres.py con varias imágenes distintas comprobamos que el \textit{threshold} adaptativo es el que mejor podría funcionar, pero al empezar a probar, rápidamente nos damos cuenta de que no va a ser así ya que, independientemente de los parámetros que tomemos, algunos de los colores se quedan en blanco y en varias imágenes llegan a hacer que el rectángulo quede dividido en dos partes (véase \textit{Figura \ref{adapThresh}}).

\begin{figure}[h]
\begin{center}
\includegraphics[width=10cm]{imagenes/Imagen2.png}
\end{center}
\caption{Fallos en el \textit{threshold} adaptativo.}
\label{adapThresh}
\end{figure} 

Como aplicar el \textit{threshold} directamente parece que no funciona bien, guardamos una imagen del \textit{color-check} aislado (qp.jpg) y probamos con \textit{matchTemplate}. Lo que hace este método es, dado un patrón de tamaño $h\times w$, va desplazándolo sobre la imagen de tamaño $H\times W$ y comparándolos según hayamos elegido. Si por ejemplo, utilizáramos el método del cuadrado de las diferencias normalizado, lo que obtendríamos sería una nueva imagen de tamaño $(W-w+1)\times (H-h+1)$ donde cada punto representa lo parecido que es el patrón a la porción de la imagen con que lo estamos comparando, siendo 0 si son perfectamente iguales y mayor cuanto más distintas. El punto donde se encuentra el mínimo en esta nueva imagen es el valor de la esquina superior izquierda de la porción de imagen donde es más probable que se encuentre el patrón.

Aplicándolo sobre nuestras imágenes tomando como patrón la tarjeta de color, observamos que funciona muy bien, pero como los tamaños de la \textit{color-check} varían de unas imágenes a otras, no obtenemos el punto exacto donde se encuentra en la mayoría de ellas. Finalmente decidimos aprovechar este punto para reducir el área de la imagen donde buscar, quedándonos con la porción situada desde el punto hacia la derecha y hacia abajo, añádiendo un trozo por arriba y hacia la izquierda lo suficientemente grande para asegurarnos que el \textit{color-check} se encuentra en esta zona.

Como los filtros que estábamos probando no funcionaban muy bien, creamos floodfillgray.py que actúa sobre los puntos con un valor de r, g y b parecido (grises), evitando los blancos y negros. Lo utilizamos para acentuar las diferencias entre fondo y \textit{color-check}, ya que el fondo tiene un color gris neutro (véase \textit{Figura \ref{floodfillgray}}). Este filtro sí que funcina como deseábamos, acentuando el rectángulo de color sobre el fondo, y además sirve para todas las imágenes, así que es el que decido utilizar.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=10cm]{imagenes/Imagen3.png}
\end{center}
\caption{Ejemplo de funcionamiento de floodfillgray.py}
\label{floodfillgray}
\end{figure} 

Una vez que hemos conseguido separar la tarjeta de color del fondo, el siguiente paso es encontrar el contorno. Para ello utilizamos \textit{cv2.Canny} seguido de \textit{cv2.findContours}. Como el \textit{color-check} es un rectángulo, lo que hacemos para estar seguros de que el contorno seleccionado es el correcto es calcular el rectángulo de área mínima que contiene a cada uno y quedarnos con el que tenga el área y la proporción alto/ancho más parecido al del \textit{color-check} aislado que habíamos guardado.

\section{Reescalando la imagen}
Una vez que hemos encontrado el rectángulo de colores en cada imagen tenemos que reescalarlas.\\
 Vamos a hacer que todos los \textit{color-check} tengan el mismo tamaño con una simple regla de tres. Para intentar perder la menor información posible sobre las imágenes, principalmente del color, el nuevo valor de alto y ancho que vamos a elegir es la media de los altos y anchos de cada imagen.

Uniendo todo, obtenemos el programa resizeAndWrite.py que hace lo que deseábamos: encontrar en cada imagen el \textit{color-check} y utilizando éste, hacer que todas las imágenes queden a la misma escala.  

\chapter{Aislando la mariposa}
Ya que he conseguido tener todas las imágenes guardadas a la misma escala hay que encontrar una máscara o contorno de la mariposa para tenerla aislada, sin que influyan los valores del fondo ni de ningún otro elemento sobre los datos que obtengamos.

Esta parte del trabajo aparentemente era muy sencilla ya que a simple vista parecía que aplicando un simple \textit{threshold} o \textit{floodfill} sería suficiente para lograr lo que deseábamos, pero cuando nos pusimos a trabajar en ello nos dimos cuenta de que no es así. Al contrario de lo que creíamos, debido a problemas con las muestras y a la gran variedad de ejemplares (algunos muy diferentes), aislar la mariposa se convirtió en un gran problema y, por tanto, en el núcleo del trabajo.  

\section{Problemas de las muestras}
Al empezar a trabajar sobre las muestras nos surgen dos grandes problemas: las sombras en la zona inferior de las mariposas y la gran diversidad de colores.

Las sombras son un problema debido a que, al aplicar algunos métodos como canny para encontrar el borde, detecta las sombras como contorno y al aplicar otros como floodfill, hacen de ``barrera'' impidiendo que esa zona del fondo sea cubierta o que si aumentas los límites para cubrirla se tape parte de la mariposa. Aquí también entra en juego el problema de los colores, ya que si no hubiera muestras con colores claros, las sombras realmente no serían tan problemáticas, porque con disminuir el valor del límite inferior en el floodfill conseguiríamos taparlas sin entrar en el ``cuerpo'' (esto es así debido a la gran diferencia entre los valores del color del fondo y los de la mariposa). Pero como los ejemplares tienen colores muy variados en vez de evitar un problema nos encontramos con dos.

El que los ejemplares de las muestras tengan colores muy variados, aparte de no ayudar a la hora de quitar las sombras también es un problema porque metódos que funcionan bien con unos tonos no funcionan tan bien con otros (un ejemplo de ésto puede ser el ya mencionado \textit{floodfill}).

Otra de las dificultades que nos hemos encontrado es que las mariposas pueden tener muchos colores. Debido a ésto, no podemos utilizar directamente métodos como \textit{threshold} ya que si, por ejemplo, el ejemplar es marrón con alguna mancha blanca, a parte de tapar el fondo taparía también las manchas.

\section{Solución obtenida}
Después de probar muchos métodos con muchos valores diferentes y de investigar varios caminos que resultaron no ser útiles (véase sección *********) llegamos a una posible solución.

Antes de seguir y para que tarde menos en hacer los cálculos decidimos reducir el tamaño de la imagen con la que vamos a trabajar. Lo que hacemos es utilizar \textit{cv2.matchTemplate} para encontrar la esquina superior izquierda del \textit{color-check}, a este punto le restamos una constante ``a'' de forma que se ajuste lo máximo posible a la mariposa (véase \textit{Figura \ref{ajusteCte}}) (esta constante ``a'' es conocida ya que es el valor correspondiente a la parte que todavia quedaría visible de la regla, y esto es posible debido a que sabemos a que escala está la imagen).

\begin{figure}[h]
\begin{center}
\includegraphics[width=8cm]{imagenes/Imagen4.png}
\end{center}
\caption{Valor que hay que restar.}
\label{ajusteCte}
\end{figure} 

Una vez que tenemos reducida la imagen empezamos a aplicar distintos filtros, con el fin de llegar a obtener una máscara de la mariposa o bien una imagen en la que destaque ésta sobre el fondo de forma que sea fácil encontrar el contorno.

%A simple vista parece que las sombras que aparecen en la parte de abajo de las mariposas pueden dar problemas a la hora de aislarla, por ello decido investigar los distintos espacios de color para ver si hay alguno en el que la diferencia de luz no afecte sobre el color.\\
%.......CONTAR ALGO SOBRE COLOR..........

%Como no encuentro nada que me ayude decido seguir buscando otro tipo de soluciones.

\subsection{Acentuar contorno}

Una primera idea es usar floodfill (ver parte II) para separar el fondo....
pero hacía falta acentuar el contorno...


Una primera idea es usar \textit{cv2.floodfill}. Esto funciona muy bien sobre mariposas con colores oscuros, pero las que tienen colores claros nos dan problemas, ya que si tomamos valores bajos ... mirar cuales si el hi o el lo.... no tapa bien todo el fondo y si aumentamos estos valores tapa también parte de la mariposa (véase \textit{Figura \ref{claro-oscuro}}). 

\begin{figure}[ht]
\begin{center}
\includegraphics[width=15cm]{imagenes/Imagen5.png}
\end{center}
\caption{La mariposa de colores oscuros se aisla muy facilmente, sin embargo, la de colores claros se empieza a tapar rápidamente.}
\label{claro-oscuro}
\end{figure}

Como aplicar directamente el floodfill no es suficiente decidimos probar acentuando antes el contorno. Aplicamos blur y erode para acentuar los bordes de la mariposa (véase \textit{Figura \ref{blur-erode}}). Esto funciona muy bien. 

\begin{figure}[ht]
\begin{center}
\includegraphics[width=14cm]{imagenes/Imagen6.png}
\end{center}
\caption{Transformación de la imagen tras aplicar \textit{median blur} y \textit{erode}.}
\label{blur-erode}
\end{figure}

Después de ésto, aplicamos otra vez \textit{cv2.canny} para encontrar los contornos, pero viendo las imágenes que genera el canny, observamos que acentuar sólo los bordes no es suficiente para encontrar bien el contorno,
 %!!!! METER IMAGEN DEL CANNY  !!!(imagen de canny no es suf para cont pero se puede usar como mask con el flood)
pero sí que podemos aprovechar los contornos obtenidos como máscara con \textit{cv2.floodfill}. 

Gracias al uso conjunto del floodfill y canny logramos que en las imágenes con colores claros, cuando aplicamos el floodfill, sea más difícil tapar parte de la mariposa ya que no puede atravesar los contornos que hemos utilizado como máscara.


\subsection{Separar el fondo}
Finalmente, para separar el fondo vamos a aplicar varias veces seguidas el método floodfill utilizando la imagen de canny como máscara.\\
Los puntos sobre los que utilizamos este  método son, en principio, la esquina superior derecha de la imagen, para así asegurarnos de que el píxel elegido no está dentro del cuerpo de la mariposa y, como con un único punto no va a ser suficiente para cubrir todo el fondo, ya que por la zona de las reglas el color es más oscuro por las sombras, tomo varios puntos por el borde izquierdo y el inferior de la imagen que son donde surge el problema.\\
Además de sobre estos puntos el usuario puede aplicar el método tantas veces como desee para lograr que la máscara se adapte al cuerpo de la mariposa lo máximo posible.

Después de aplicar los floodfill, tenemos una imagen en BGR con el fondo en blanco y el resto en los colores correspondientes, así que, aplicamos un theshold que convierta esta imagen en una binaria.\\ 
El threshold que utilizo es \textit{THRESH\_BINARY\_INV} que nos deja el fondo negro y la mariposa en blanco, como deseábamos.

 Como una vez hecho esto el contorno es muy desigual, aplicamos \textit{cv2.erode} otra vez sobre la imagen para que el borde se suavice y de esta forma se eliminen posibles zonas blancas aisladas que haya en el fondo.

Juntando todo obtengo el programa calcBinaryImage.py que se divide en cuatro partes fundamentales:
\begin{itemize}
\item Un primer filtrado para acentuar los bordes de las mariposas.
\item Encontrar los contornos para utilizarlos porteriormente junto con \textit{cv2.floodfill}.
\item Varios floodfill para tapar el fondo.
\item Un filtro posterior para eliminar pequeños fallos del \textit{floodfill} y suavizar los bordes de la máscara.
\end{itemize}


\section{Algunos caminos no fructíferos}
ESTO NO SE DONDE PONERLO??
El primer objetivo del trabajo era encontrar un programa que funcionara de forma automática y, aunque no es un camino no fructífero si que es un objetivo que no hemos logrado. Debido a los diversos problemas de las muestras, encontramos muchas dificultades a la hora de encontrar unos datos que funcionasen correctamente con todas las imágenes y que a su vez, taparan las sombras. Por ello, en vez de lograr una solución que hiciera todo el trabajo de forma automática hemos logrado que lo haga de forma semiautomática, así al aplicar los floodfill el usuario puede elegir puntos extra para adaptar mejor la máscara y eliminar las sombras que no se hayan tapado y también puede variar las constantes elegidas para cada método.\\
El valor de las constantes que dejamos por defecto funciona bien con casi todas las imágenes, pero si en alguna el usuario no obtiene lo que deseába o cree que se puede mejorar, puede cambiar estos valores para obtener soluciones más precisas.

Otros de los caminos que investigamos y de los que no obtuvimos ninguna solución fueron, los espacios de color y el programa floodfillgray.py.

\subsection{Espacios de color}
Lo que pretendíamos al investigar los distintos espacios de color era encontrar uno en el que pudiéramos obtener el valor de los colores independientemente de su luminosidad, para que de esta forma, la sombra no supusiera un problema a la hora de aislar la mariposa.

Investigamos distintos espacios como el YCrCb o el CIELab, donde una de sus componentes es la luminosidad. En concreto, en YCrCb son luminosidad, cantidad de color azul y cantidad de color rojo, y en CIELab son luminosidad, posición entre rojo y verde y posición entre amarillo y azul.

Creamos inkwell.py y hicimos muchas pruebas, pero no encontramos ninguna ventaja si utilizábamos alguno de estos espacios en vez de RGB. Así que finalmete decidimos quedarnos en RGB.

\subsection{floodfillgray.py}
La idea de este programa es separar el fondo utilizando el hecho de que es de color gris. Lo que hace es ir píxel a píxel comparando los valores de R, G y B. Por tanto, $\forall i,j$ (píxel) tenemos $R_{i,j}$, $G_{i,j}$ y $B_{i,j}$. Pintamos aquellos píxeles que cumplan $Max\{R_{i,j}, G_{i,j}, B_{i,j}\} - Min\{R_{i,j}, G_{i,j}, B_{i,j}\}<\varepsilon$ (son de color gris), $linf<\frac{R_{i,j}+G_{i,j}+B_{i,j}}{3}<lsup$ (descartamos los blancos y negros).

Este programa fallaba en muchas muestras, en todas aquellas que tuvieran colores grises, por eso hubo que descartarle.

A pesar de que para aislar la mariposa no servía, el programa funcionaba muy bien y lo usamos para encontrar el color-check. 


\chapter{Comparando las imágenes}
Recordemos que el objetivo es que dada una nueva imagen el programa nos muestre las más parecidas a ésta, centrándonos principalmente en el estudio del color y la forma. Por tanto, una vez que ya tengo todas las imágenes a la misma escala y he encontrado la máscara de cada una de ellas puedo empezar a realizar las comparaciones.

\section{Por color}
Las comparaciones por color las vamos a hacer utilizando histogramas. Lo que hacemos es utilizar la máscara para restringir la zona de la imagen sobre la cual se calcula el histograma. Después se normaliza. Al haberlo normalizado se van a seleccionar mariposas con los mismos colores independientemente de si son más grandes o más pequeñas, ya que ahora sólo nos importa el color (cuando apliquemos porteriormente el análisis de la forma ya descartaremos las que tengan un tamaño distinto).

Una vez que tenemos calculados todos los histogramas empiezamos a compararlos uno por uno con el de la imagen que deseamos introducir. Esto lo vamos a llevar a cabo utilizando \textit{cv2.compareHist}.\\
Dividimos la imágen en tres capas (azul, verde, roja) y comparamos los histogramas capa por capa. De cada comparación obtenemos un valor que nos va a indicar cómo de parecidas son las imágenes en esa capa, de forma que, si son lo suficientemente parecidas en las tres capas la imagen es seleccionada y si hay una capa en la que no se parece se descarta. Esto tiene que ser así porque si no diríamos que una imagen amarilla (con el máximo de rojo y de verde) es parecida a una blanca, ya que también tiene el máximo de rojo y verde y sólo se diferenciaría en la capa azul.

Para las comparaciones que se realizan con \textit{cv2.compareHist} podemos elegir varios métodos. En nuestro caso, hemos elegido el de comparación por correlación y chi cuadrado (CV\_COMP\_CORREL y CV\_COMP\_CHISQR), el primero funciona un poco peor pero más rápido y el segundo al revés, más lento pero un poco mejor. 
\\Con el método de comparación por correlación, cuanto más próximo es el valor a 1 más parecidas son las imágenes y en el método de la chi-cuadrado, es mejor cuanto más próximo a 0.

El programa que realiza todo esto es searchByColor.py y tiene dos pasos principales:
\begin{itemize}
\item Encontrar las máscaras de cada imagen utilizando calcBinaryImg.py.
\item Comparar una por una cada imagen con la que deseamos introducir utilizando los histogramas de cada una de ellas.
\end{itemize}

\section{Por forma}
Las comparaciones por forma las vamos a hacer de varias maneras diferentes para quedarnos posteriormente con la que mejor resultados proporcione. Básicamente, van a ser con diferentes métodos a partir de la máscara o imagen binaria y a partir de los contornos. 
\subsection{Con imagen binaria}
El primer método que vamos a emplear se basa en los momentos de una imagen.\\
Estos momentos se sacan a partir de un contorno o de una imagen binaria y nos proporcionan unos valores que representan distintas propiedades de la imagen. Los que vamos a utilizar son los momentos de Hu y los momentos centrales normalizados que son invariantes a traslación, escalado y rotación, y a traslación y escalado respectivamente.\\
Las funciones que calculan estos momentos son \textit{cv2.HuMoments} y \textit{cv2.moments}.
\subsubsection{Momentos de Hu}
Como ya he dicho, estos momentos son invariantes a traslación, escalado y rotación y los vamos a calcular a partir de la imagen binaria obtenida tras aplicar calcBinaryImg.py a las imágenes de la base de datos.

Primero se calculan todos los momentos con \textit{cv2.moments} y después a partir de éstos, se calculan los momentos de Hu con \textit{cv2.HuMomets}. De aquí se obtienen seis valores que van a ser los que utilicemos para la comparación.\\
Lo primero que vamos a hacer es calcular estos seis valores $V_1,...,V_6$ de la imagen del nuevo ejemplar, y una vez que tenemos éstos, vamos calculando uno por uno los $v_1,...,v_6$ del resto.\\
 Cada vez que calculamos los momentos de una nueva imagen los comparamos con los que tenemos del nuevo ejemplar, de forma que sólo seleccionamos la imagen si $v_i\in(V_i-eps_i,V_i+eps_i)$ $ \forall i\in\{1,..,6\}$ siendo cada $eps_i$ una constante que elige el usuario y que sirve para exigir que se parezcan mucho ($eps_i$ muy bajo) o permitir más diferencias ($eps_i$ más alto).

Las pruebas realizadas utilizando estos momentos no dan muy buenos resultados, ya que resultan seleccionados muchos ejemplares que en realidad, mirando las imágenes y las correspondientes máscaras directamente, no se parecen.

A la vista de estos resultados decidimos probar con otros momentos: los momentos centrales normalizados.

\subsubsection{Momentos centrales normalizados}
 Éstos no son invariantes a rotación, algo que puede beneficiarnos, ya que si lo permitiésemos, podríamos obtener ``falsos positivos'', como por ejemplo, seleccionar una imagen que es igual a la que tenemos pero girada $180^{o}$.  !!! METER IMAGEN !!!

El funcionamiento de este método es análogo al de los momentos de Hu.

.....COMENTAR ALGO DE COMO FUNCIONA, BIEN O MAL....

\subsection{Con contornos}
Para el resto de métodos vamos a usar principalmente los contornos de la mariposa.

Hasta ahora teníamos un programa que calculaba una imagen binaria de la mariposa (calcBinaryImg.py) y como ahora no nos sirve con esto, vamos a utilizar esta imagen para calcular los contornos que necesitamos.

Lo primero que vamos a hacer es aplicar \textit{cv2.canny} y \textit{cv2.findContours} a la máscara. Una vez hecho esto observamos que no todos los cotornos que salen están unidos, es decir, lo que necesitamos es tener el contorno de la mariposa en un único trazado continuo y cerrado, pero en muchos casos no se cierra o incluso no ``bordea'' toda la mariposa.\\
Esto es un problema porque la idea principal era utilizar el área de los contornos para compararlos con el área de la mariposa (este área no es conocido pero podemos aproximarlo al momento m00 que es el número de píxeles blancos de la imagen binaria) y de esta forma poder seleccionar el que necesitaba, pero al no tener contornos cerrados no puedemos utilizar \textit{cv2.contArea} ya que no proporciona datos fiables. 

Necesitamos otra forma de poder seleccionar el contorno de la mariposa. Decidimos probar utilizando el área del rectángulo y la circunferencia de mínimo área que contienen a cada contorno. Nos vamos a quedar con el mínimo de estos y lo vamos a llamar ``A''. A siempre va a ser mayor que el area de la mariposa, que vamos a llamar ``a'', así que, al compararlos hay que tenerlo en cuenta, de tal forma que, nos vamos a quedar con ese contorno si ¿¿¿¿¿¿$A<2a$???????(creo que esta condición se puede quitar ya que no va puede haber ningún contorno que tenga el valor de A mayor que el del A que contiene al contorno de la mariposa) y $A>a-a/2$, con la primera condición descartamos los que son muy grandes y con la segunda los que son pequeños.

Si utilizáramos sólo este método podría darse el caso de que nos quedáramos con un contorno que no está cerrado y existiera uno que si lo estuviera, y como si hay uno cerrado lo vamos a preferir siempre ante uno abierto (ya que cerrado nos proporciona más información), vamos a utilizar conjuntamente el método del área del contorno y el del área del rectángulo y la circunferencia para seleccionar el contorno de la mariposa.\\
De cada contorno se calcula su área, si éste se parece al de la mariposa (es decir, es igual al de la mariposa +/- una cte que elige el usuario) nos quedamos con éste y no miramos más, si no, lo comparamos por el método del rectángulo y la circunferencia. Si por éste método es seleccionado, lo guardamos y pasamos al siguiente. Si al final no se ha encontrado ninguno cerrado nos quedamos con el del método del rectángulo y la circunferencia.

Esta forma de encontrar cual es el contorno de la mariposa funciona bastante bien, así que es el que finalmente utilizamos.

Una vez que tenemos los contornos de cada mariposa hay que empezar a compararlos, en este caso, lo vamos a hacer de dos formas diferentes.

\subsubsection{matchShapes}
El primer método que vamos a utilizar es basándonos en matchShapes. Lo que hace esta función es comparar dos contornos, es decir, dados dos contornos y la norma que queremos que utilice, devuelve un valor que representa cómo de parecidos son. Cuanto más proximo a 0 sea el valor más parecidos son los contornos.

En el programa de comparación por la forma lo que hacemos es calcular este valor con tres normas diferentes obteniendo así $v_1$, $v_2$, $v_3$ y compararlo con tres constantes $c_1$,$c_2$ y $c_3$ dadas por el usuario. Consideramos que los contornos son suficientemente parecidos y seleccionamos la imagen cuando $v_i<c_i \forall i\in\{1,2,3\}$.

\subsubsection{Otros momentos}
El otro método que vamos a probar se basa en las distintas propiedades de los contornos y de la máscara de las mariposas. Se trata de crear una lista con nuestros ``propios'' momentos y utilizar esta lista para hacer la comparación igual que usábamos los tres valores de \textit{cv2.matchShapes}.

Las propiedades que voy a utilizar son: 
\begin{enumerate}
\item El número de píxeles en blanco o momento m00.
\item El área y el perímetro del contorno.
\item La proporción entre el ancho y el alto del rectángulo de mínimo área que contiene al contorno.
\item La proporción entre el área del contorno y el área del rectángulo de mínimo área que lo contiene.
\item La proporción entre el área del contorno y el área de la figura convexa de míninimo área que lo contiene.
\item El diámetro del círculo cuyo área es el mismo que el del contorno. Éste diámetro es $\sqrt{4*A/\pi}$ siendo A el área del contorno.
\end{enumerate}
Estos valores son muy fáciles de obtener usando las funciones \textit{cv2.contourArea}, \textit{cv2.arcLength}, \textit{cv2.boundingRect} y \textit{cv2.convexHull} que calculan el área y perímetro del contorno y el rectácgulo de mínimo área y figura convexa de mínimo área que lo contienen respectivamente.

Éstos momentos serían muy fáciles de utilizar si tuviéramos un contorno cerrado y continuo para todas las imágenes.Como no hemos conseguido obtener el contorno de dicha manera resulta muy difícil o casi imposible calcular algunos de ellos, ya que, por ejemplo, \textit{cv2.contourArea} no nos daría el área real del contorno por no estar cerrado.

.....REVISAR ESTA PARTE....\\
Para poder utilizar este método tenemos que seguir investigando la forma de obtener un contorno continuo y cerrado para todas las imágenes.

 Como de momento no lo hemos conseguido decidimos crear searchBySize\_contour.py que compara las imágenes por forma utilizando \textit{cv2.matchShapes} y los momentos 1, 3 y 6 (en 3 en vez de tomar el área del contorno que devuelve la función \textit{cv2.contourArea} utilizo el momento m00).

\chapter{Aplicación final}

***Hablar algo del interfaz****

Ya tenemos creados los programas que seleccionan, dentro de una colección de imágenes de mariposas, las más parecidas a otra dada fjándonos en el color y la forma. Ahora hay que juntar los dos métodos para que la criba sea lo más precisa posible.

Al tener ya creados searchByColor.py y searchBySize.py hacer esto es muy sencillo. Creamos search.py que lo que hace es filtrar primero una colección de imágenes por forma y las que son seleccionadas las filtra, posteriormente, por color o viceversa (según el orden que elija el usuario). Obteniendo de esta manera, al final del proceso, el conjunto de imágenes deseado.
   
\chapter{Conclusiones}
%hablar de lo del fondo y las sombras. De lo de los contornos discontinuos. De la dificultad hasta encontrar la máscara.De seguir investigando hasta encontrar un contorno continuo.


\appendix
\chapter{Conceptos generales del tratamiento de imágenes}
OpenCV (Open source Computer Vision library) es una librería de Visión Computarizada, destinada al tratamiento de imágenes y, principalmente, a la visión por computador en tiempo real.

Detrás de la mayoría de las funciones de la librería que voy a utilizar se encuentran gran cantidad de cálculos, fórmulas y, en definitiva, métodos matemáticos. Por ello, en esta primera parte, voy a explicar las principales funciones de OpenCV que van a ser necesarias en la segunda parte para desarrollar el proyecto, centrándome principalmente en entender su funcionamiento y tratar de explicar algo sobre las matemáticas que hay detrás.

Antes de empezar, es conveniente explicar que un ordenador ``ve'' una imagen como una matriz, donde en cada posición hay tres números, el valor del color rojo, verde y azul (cada elemento de la matriz representa un píxel). Otra forma de verlo es como si la imagen se separara en tres matrices o ``capas'', una la de los valores del color rojo, otra verde y otra azul.\\
En imágenes en escala de grises sólo habría una matriz donde cada número representa el valor del gris en ese píxel.

 **** IMAGEN *****

El trabajo lo he desarrollado utilizando python 2.7 y OpenCV 2.3.1.

\section{Filtrado de imágenes}
****Explicar lo de la complejidad y la transformada de Fourier*********\\

Tenemos una imagen y queremos aplicar sobre ella un filtro. Los filtros que vamos a usar lo que hacen es, dada la imagen y un núcleo, se desplaza píxel por píxel sobre la imagen comparando los valores de la posición $(i,j)$ con todos los del núcleo y obteniendo uno nuevo. El valor que tenía el píxel $(i,j)$ se cambia por el nuevo. Dependiendo del método que utilicemos el núcleo tendrá tamaños diferentes pudiendo llegar a ser de tamaño $1\times1$ y el método de comparación también será distinto.

\subsection {Smoothing}
Estos filtros se utilizan frecuentemente y se usan principalmente para eliminar ruido de las imágenes o reducir la resolución. Hay muchos tipos pero ahora vamos a centrarnos sólo en uno, ya que es el que más utilizamos a lo largo del documento, median blur.

En el programa smoothing.py se pueden ver ejemplos con varios métodos diferentes.

\subsubsection {Median blur}
En este caso, no hay que dar un núcleo concreto, sólo hay que dar el tamaño deseado, supongamos $k$ con $k\ge 1$ impar. El núcleo será igual a la porción de imagen de tamaño $k\times k$ coincidiendo el centro con el píxel $(i,j)$. Lo que hace es ir recorriendo toda la imagen de forma que en la posición $(i,j)$, $a_{i,j}$ ahora será igual a la media de todos los valores del núcleo, es decir, $ a_{i,j} = \displaystyle\sum_{n = i-\frac{k-1}{2}}^{i+\frac{k-1}{2}}\displaystyle\sum_{m = j-\frac{k-1}{2}}^{j+\frac{k-1}{2}} \frac{b_{n,m}}{k^2}$.

*********  EJEMPLO  ***********

\subsection {Erode y dilate}
Los filtros erode y dilate se utilizan para eliminar ruido, aislar y juntar elementos, etc. También pueden utilizarse para encontrar contornos en una imagen.

Dado el tamaño del núcleo y el punto de éste donde queremos centrar cada píxel (por defecto es el centro del núcleo), se recorre toda la imagen calculando para cada posición un nuevo valor que varía dependiendo de si es erode o dilate:
\begin{itemize}
\item{\bfseries{Erode:}}
\\$a_{i,j} = Min_{n,m}\{a_{n,m}\}$ con $n\in [i-\frac{k-1}{2},i+\frac{k-1}{2}]$ y $m\in [j-\frac{k-1}{2},j+\frac{k-1}{2}]$

Al tomar el valor mínimo lo que se logra es oscurecer la imagen o agrandar las zonas oscuras. 
\item{\bfseries{Dilate:}}
\\$a_{i,j} = Max_{n,m}\{a_{n,m}\}$ con $n\in [i-\frac{k-1}{2},i+\frac{k-1}{2}]$ y $m\in [j-\frac{k-1}{2},j+\frac{k-1}{2}]$

Al tomar el valor máximo lo que se logra es aclarar la imagen o agrandar las zonas claras.

\end{itemize}
 
\subsection {Threshold}

\subsection{Floodfill}
\section{Análisis de imágenes}
\subsection{Espacios de color}
\subsection{Histogramas}
\section{Encontrar bordes}
\subsection{canny}

\chapter{Code}
hola
{\tiny
hola
\lstinputlisting{calcBinaryImage.py}}

\chapter{Pruebas}


\end{document}
